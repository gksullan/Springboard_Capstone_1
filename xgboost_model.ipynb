{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns=1000\n",
    "pd.options.display.width=200\n",
    "pd.options.display.min_rows=60\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, define some functions we can use to run the models\n",
    "\n",
    "def preprocess_data(df):\n",
    "    '''\n",
    "    function to remove non-numeric features and null values\n",
    "    input: dataframe\n",
    "    outputs: df & var_class=Series with class labels popped from df\n",
    "    '''\n",
    "    \n",
    "    #select only columns with int or float data types\n",
    "    df = df.select_dtypes(['number'])\n",
    "    #drop any columns with null values\n",
    "    df.dropna(axis=1,inplace=True)\n",
    "    #remove the class series\n",
    "    var_class = df.pop('CLASS')\n",
    "    #create a Dmatrix (specific for xgboost)\n",
    "    data_dmatrix = xgb.DMatrix(data=df, label=var_class)\n",
    "    \n",
    "    return df, var_class, data_dmatrix\n",
    "\n",
    "def compare_dicts(a,b,ignore=['test_score', 'train_score', 'tn', 'fn', 'tp', 'fp',\n",
    "                              'f1_score', 'precision', 'recall', 'feature_importances']):\n",
    "    '''\n",
    "    function to compare if current hyperparameters have already been run in a model\n",
    "    inputs: a=hyperparameter entry, b=current hyperparameters, ignore=hyperparameters to ignore in comparison\n",
    "    output: boolean, True if the current hyperparameters have been run already, and False if they have not\n",
    "    '''\n",
    "    \n",
    "    a = dict(a)\n",
    "    b = dict(b)\n",
    "    for k in ignore:\n",
    "        a.pop(k,None)\n",
    "        b.pop(k,None)\n",
    "        \n",
    "    return tuple(a.items()) == tuple(b.items())\n",
    "\n",
    "def make_comparison(hyperparam_table, hyper_dict, compare_func=compare_dicts):\n",
    "    '''\n",
    "    function to compare current hyperparameters (hyper_dict) to existing hyperparam_table\n",
    "    inputs: hyperparam_table, hyper_dict\n",
    "    outputs: exists=True if hyper_dict has been run before and False if it hasn't & hyper_dict\n",
    "    '''\n",
    "    \n",
    "    exists = any([compare_func(a, b=hyper_dict) for a in hyperparam_table])\n",
    "    return exists, hyper_dict\n",
    "    \n",
    "def train_test_write(x_train,x_test,y_train,y_test, filename, scaled=False):\n",
    "    '''\n",
    "    function to write train and test sets to files\n",
    "    inputs: train and test dfs & scaled=False if no scaling, True if scaling\n",
    "    output: None\n",
    "    '''\n",
    "    \n",
    "    if scaled:\n",
    "        x_train.to_csv(filename[:-4]+'_scaledxtrain.csv')\n",
    "        x_test.to_csv(filename[:-4]+'_scaledxtest.csv')\n",
    "        y_train.to_csv(filename[:-4]+'_scaledytrain.csv',header=False)\n",
    "        y_test.to_csv(filename[:-4]+'_scaledytest.csv',header=False)\n",
    "    else:\n",
    "        x_train.to_csv(filename[:-4]+'_xtrain.csv')\n",
    "        x_test.to_csv(filename[:-4]+'_xtest.csv')\n",
    "        y_train.to_csv(filename[:-4]+'_ytrain.csv',header=False)\n",
    "        y_test.to_csv(filename[:-4]+'_ytest.csv',header=False)\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test, hyper_dict, hyperparam_table):\n",
    "    '''\n",
    "    function to train model with given training/test sets and hyperparameters\n",
    "    inputs: x_train, y_train, x_test, y_test, hyper_dict=dict of current hyperparameters to be run, hyperparam_table=table of hyperparameters already run\n",
    "    outputs: clf=classifier trained & hyperparam_table updated\n",
    "    '''\n",
    "    \n",
    "    hyperparam_table += [hyper_dict]\n",
    "    clf = hyper_dict['model'](class_weight=hyper_dict['class_weight'], random_state=hyper_dict['random_state'])\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    predictions_test = [round(x) for x in clf.predict(x_test)]\n",
    "    predictions_train = [round(x) for x in clf.predict(x_train)]\n",
    "    \n",
    "    score = clf.score(x_test,y_test)\n",
    "    hyperparam_table[-1]['test_score'] = score\n",
    "    training_score = clf.score(x_train,y_train)\n",
    "    hyperparam_table[-1]['train_score'] = training_score\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,predictions_test).ravel()\n",
    "    hyperparam_table[-1]['tn'] = tn\n",
    "    hyperparam_table[-1]['fp'] = fp\n",
    "    hyperparam_table[-1]['fn'] = fn\n",
    "    hyperparam_table[-1]['tp'] = tp\n",
    "    \n",
    "    f1 = f1_score(y_test,predictions_test)\n",
    "    hyperparam_table[-1]['f1_score'] = f1\n",
    "    precision = precision_score(y_test,predictions_test)\n",
    "    hyperparam_table[-1]['precision'] = precision\n",
    "    recall = recall_score(y_test,predictions_test)\n",
    "    hyperparam_table[-1]['recall'] = recall\n",
    "    \n",
    "    hyperparam_table[-1]['feature_importances'] = clf.feature_importances_\n",
    "    \n",
    "    return clf, hyperparam_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty hyperparameter table\n",
    "hyperparam_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0,38,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# run a xgboost model on raw data before any data cleaning/feature engineering\n",
    "filename = 'data/clinvar_conflicting.csv'\n",
    "df =  pd.read_csv(filename)\n",
    "df, var_class, data_dmatrix = preprocess_data(df)\n",
    "\n",
    "hyper_dict = {'test_size': 0.05, \n",
    "              'random_state': 0, \n",
    "              'data_size': str(df.shape),\n",
    "              'scaling': None,\n",
    "              'filename': filename,\n",
    "              'model': XGBClassifier,\n",
    "              'class_weight': None\n",
    "             }\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,var_class,\n",
    "                                                 test_size=hyper_dict['test_size'],\n",
    "                                                 random_state=hyper_dict['random_state'])\n",
    "\n",
    "train_test_write(x_train,x_test,y_train,y_test, filename, scaled=False)\n",
    "exists, hyper_dict = make_comparison(hyperparam_table, hyper_dict, compare_func=compare_dicts)\n",
    "if not exists: \n",
    "    clf, hyperparam_table = train_model(x_train, y_train, x_test, y_test, hyper_dict, hyperparam_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>data_size</th>\n",
       "      <th>scaling</th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.24821</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state   data_size scaling                      filename                                    model class_weight  test_score  train_score    tn   fp   fn   tp  f1_score  precision  \\\n",
       "0       0.05             0  (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.761656      0.79326  2275  147  630  208  0.348701   0.585915   \n",
       "\n",
       "    recall                              feature_importances  \n",
       "0  0.24821  [0.13841417, 0.11646682, 0.33226815, 0.4128508]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp = pd.DataFrame(hyperparam_table)\n",
    "df_hyp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# balance the class weights\n",
    "filename = 'data/clinvar_conflicting.csv'\n",
    "df =  pd.read_csv(filename)\n",
    "df, var_class, data_dmatrix = preprocess_data(df)\n",
    "\n",
    "hyper_dict = {'test_size': 0.05, \n",
    "              'random_state': 0, \n",
    "              'data_size': str(df.shape),\n",
    "              'scaling': None,\n",
    "              'filename': filename,\n",
    "              'model': XGBClassifier,\n",
    "              'class_weight': 'balanced'\n",
    "             }\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,var_class,\n",
    "                                                 test_size=hyper_dict['test_size'],\n",
    "                                                 random_state=hyper_dict['random_state'])\n",
    "\n",
    "train_test_write(x_train,x_test,y_train,y_test, filename, scaled=False)\n",
    "exists, hyper_dict = make_comparison(hyperparam_table, hyper_dict, compare_func=compare_dicts)\n",
    "if not exists: \n",
    "    clf, hyperparam_table = train_model(x_train, y_train, x_test, y_test, hyper_dict, hyperparam_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (34,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Use cleaned data file with NLP features\n",
    "filename = 'data/data_cleanednlp4.csv'\n",
    "df =  pd.read_csv(filename)\n",
    "df, var_class, data_dmatrix = preprocess_data(df)\n",
    "\n",
    "hyper_dict = {'test_size': 0.05, \n",
    "              'random_state': 0, \n",
    "              'data_size': str(df.shape),\n",
    "              'scaling': None,\n",
    "              'filename': filename,\n",
    "              'model': XGBClassifier,\n",
    "              'class_weight': None\n",
    "             }\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df,var_class,\n",
    "                                                 test_size=hyper_dict['test_size'],\n",
    "                                                 random_state=hyper_dict['random_state'])\n",
    "\n",
    "train_test_write(x_train,x_test,y_train,y_test, filename, scaled=False)\n",
    "exists, hyper_dict = make_comparison(hyperparam_table, hyper_dict, compare_func=compare_dicts)\n",
    "if not exists: \n",
    "    clf, hyperparam_table = train_model(x_train, y_train, x_test, y_test, hyper_dict, hyperparam_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>data_size</th>\n",
       "      <th>scaling</th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.248210</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.248210</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 61)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/data_cleanednlp4.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.765031</td>\n",
       "      <td>0.818208</td>\n",
       "      <td>2227</td>\n",
       "      <td>195</td>\n",
       "      <td>571</td>\n",
       "      <td>267</td>\n",
       "      <td>0.410769</td>\n",
       "      <td>0.577922</td>\n",
       "      <td>0.318616</td>\n",
       "      <td>[0.01426685, 0.022147033, 0.055169754, 0.07037...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state    data_size scaling                      filename                                    model class_weight  test_score  train_score    tn   fp   fn   tp  f1_score  \\\n",
       "0       0.05             0   (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.761656     0.793260  2275  147  630  208  0.348701   \n",
       "1       0.05             0   (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>     balanced    0.761656     0.793260  2275  147  630  208  0.348701   \n",
       "2       0.05             0  (65188, 61)    None     data/data_cleanednlp4.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.765031     0.818208  2227  195  571  267  0.410769   \n",
       "\n",
       "   precision    recall                                feature_importances  \n",
       "0   0.585915  0.248210    [0.13841417, 0.11646682, 0.33226815, 0.4128508]  \n",
       "1   0.585915  0.248210    [0.13841417, 0.11646682, 0.33226815, 0.4128508]  \n",
       "2   0.577922  0.318616  [0.01426685, 0.022147033, 0.055169754, 0.07037...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp = pd.DataFrame(hyperparam_table)\n",
    "df_hyp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_co...\n",
       "                                           verbosity=None),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'colsample_bytree': [0.5, 0.7, 0.9,\n",
       "                                                             1.0],\n",
       "                                        'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [5, 7, 10, None],\n",
       "                                        'n_estimators': [5, 10, 15]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='balanced_accuracy',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use RandomSearchCV to find the best hyperparameters for this model\n",
    "\n",
    "param_dist = {'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "              \"max_depth\": [5, 7, 10, None],\n",
    "              \"colsample_bytree\": [0.5, 0.7, 0.9, 1.0],\n",
    "              \"n_estimators\": [5, 10, 15],\n",
    "              \"gamma\": [0, 0.1, 0.2, 0.3, 0.4, 0.5]}\n",
    "\n",
    "# Instantiate a XGBoost classifier\n",
    "clf = XGBClassifier(random_state=0)\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "clf_cv = RandomizedSearchCV(clf, param_dist, scoring='balanced_accuracy', cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "clf_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Parameters: {'n_estimators': 10, 'max_depth': 7, 'learning_rate': 0.3, 'gamma': 0.3, 'colsample_bytree': 0.5}\n",
      "Best score is 0.5688577252074748\n"
     ]
    }
   ],
   "source": [
    "# preview the best parameters and score\n",
    "print(f\"Tuned XGBoost Parameters: {clf_cv.best_params_}\")\n",
    "print(f\"Best score is {clf_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = clf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this model with the best params, predict labels on test data\n",
    "hyper_dict = {'test_size': 0.05, \n",
    "              'random_state': 0, \n",
    "              'data_size': str(df.shape),\n",
    "              'scaling': None,\n",
    "              'filename': filename,\n",
    "              'model': XGBClassifier\n",
    "             }\n",
    "clf = XGBClassifier(random_state=0)\n",
    "clf.set_params(**cv_params)\n",
    "hyper_dict.update(cv_params)\n",
    "hyperparam_table += [hyper_dict]\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "score = clf.score(x_test,y_test)\n",
    "hyperparam_table[-1]['test_score'] = score\n",
    "training_score = clf.score(x_train,y_train)\n",
    "hyperparam_table[-1]['train_score'] = training_score\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,pred).ravel()\n",
    "hyperparam_table[-1]['tn'] = tn\n",
    "hyperparam_table[-1]['fp'] = fp\n",
    "hyperparam_table[-1]['fn'] = fn\n",
    "hyperparam_table[-1]['tp'] = tp\n",
    "\n",
    "f1 = f1_score(y_test,pred)\n",
    "hyperparam_table[-1]['f1_score'] = f1\n",
    "precision = precision_score(y_test,pred)\n",
    "hyperparam_table[-1]['precision'] = precision\n",
    "recall = recall_score(y_test,pred)\n",
    "hyperparam_table[-1]['recall'] = recall\n",
    "\n",
    "hyperparam_table[-1]['feature_importances'] = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>data_size</th>\n",
       "      <th>scaling</th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>feature_importances</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>colsample_bytree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.248210</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.248210</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 61)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/data_cleanednlp4.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.765031</td>\n",
       "      <td>0.818208</td>\n",
       "      <td>2227</td>\n",
       "      <td>195</td>\n",
       "      <td>571</td>\n",
       "      <td>267</td>\n",
       "      <td>0.410769</td>\n",
       "      <td>0.577922</td>\n",
       "      <td>0.318616</td>\n",
       "      <td>[0.01426685, 0.022147033, 0.055169754, 0.07037...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 61)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/data_cleanednlp4.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767485</td>\n",
       "      <td>0.809537</td>\n",
       "      <td>2280</td>\n",
       "      <td>142</td>\n",
       "      <td>616</td>\n",
       "      <td>222</td>\n",
       "      <td>0.369384</td>\n",
       "      <td>0.609890</td>\n",
       "      <td>0.264916</td>\n",
       "      <td>[0.017879914, 0.0323751, 0.042251986, 0.131292...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 61)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/data_cleanednlp4.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759509</td>\n",
       "      <td>0.771057</td>\n",
       "      <td>2311</td>\n",
       "      <td>111</td>\n",
       "      <td>673</td>\n",
       "      <td>165</td>\n",
       "      <td>0.296230</td>\n",
       "      <td>0.597826</td>\n",
       "      <td>0.196897</td>\n",
       "      <td>[0.017608736, 0.05807626, 0.07068433, 0.166812...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state    data_size scaling                      filename                                    model class_weight  test_score  train_score    tn   fp   fn   tp  f1_score  \\\n",
       "0       0.05             0   (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.761656     0.793260  2275  147  630  208  0.348701   \n",
       "1       0.05             0   (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>     balanced    0.761656     0.793260  2275  147  630  208  0.348701   \n",
       "2       0.05             0  (65188, 61)    None     data/data_cleanednlp4.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.765031     0.818208  2227  195  571  267  0.410769   \n",
       "3       0.05             0  (65188, 61)    None     data/data_cleanednlp4.csv  <class 'xgboost.sklearn.XGBClassifier'>          NaN    0.767485     0.809537  2280  142  616  222  0.369384   \n",
       "4       0.05             0  (65188, 61)    None     data/data_cleanednlp4.csv  <class 'xgboost.sklearn.XGBClassifier'>          NaN    0.759509     0.771057  2311  111  673  165  0.296230   \n",
       "\n",
       "   precision    recall                                feature_importances  n_estimators  max_depth  learning_rate  gamma  colsample_bytree  \n",
       "0   0.585915  0.248210    [0.13841417, 0.11646682, 0.33226815, 0.4128508]           NaN        NaN            NaN    NaN               NaN  \n",
       "1   0.585915  0.248210    [0.13841417, 0.11646682, 0.33226815, 0.4128508]           NaN        NaN            NaN    NaN               NaN  \n",
       "2   0.577922  0.318616  [0.01426685, 0.022147033, 0.055169754, 0.07037...           NaN        NaN            NaN    NaN               NaN  \n",
       "3   0.609890  0.264916  [0.017879914, 0.0323751, 0.042251986, 0.131292...          15.0       10.0           0.25    0.4               0.5  \n",
       "4   0.597826  0.196897  [0.017608736, 0.05807626, 0.07068433, 0.166812...          10.0        7.0           0.30    0.3               0.5  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp = pd.DataFrame(hyperparam_table)\n",
    "df_hyp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
