{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns=1000\n",
    "pd.options.display.width=200\n",
    "pd.options.display.min_rows=60\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from datetime import datetime\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# import custom functions from hyperparamfuncs.py\n",
    "from hyperparamfuncs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty hyperparameter table\n",
    "hyperparam_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3249: DtypeWarning: Columns (0,38,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/home/gksullan/Documents/Springboard/Capstone_Project_1/conflicting_geneticvariants/hyperparamfuncs.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# run a xgboost model on raw data before any data cleaning/feature engineering\n",
    "filename = 'data/clinvar_conflicting.csv'\n",
    "hyper_dict = {'test_size': 0.05, \n",
    "              'random_state': 0, \n",
    "              'data_size': None,\n",
    "              'scaling': None,\n",
    "              'filename': filename,\n",
    "              'model': XGBClassifier,\n",
    "              'class_weight': None\n",
    "             }\n",
    "clf, hyperparam_table = train_eval(filename, hyper_dict, hyperparam_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>data_size</th>\n",
       "      <th>scaling</th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.79326</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.24821</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state   data_size scaling                      filename                                    model class_weight  test_score  train_score    tn   fp   fn   tp  f1_score  precision  \\\n",
       "0       0.05             0  (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.761656      0.79326  2275  147  630  208  0.348701   0.585915   \n",
       "\n",
       "    recall                              feature_importances  \n",
       "0  0.24821  [0.13841417, 0.11646682, 0.33226815, 0.4128508]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp = pd.DataFrame(hyperparam_table)\n",
    "df_hyp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance the class weights\n",
    "filename = 'data/clinvar_conflicting.csv'\n",
    "hyper_dict = {'test_size': 0.05, \n",
    "              'random_state': 0, \n",
    "              'data_size': None,\n",
    "              'scaling': None,\n",
    "              'filename': filename,\n",
    "              'model': XGBClassifier,\n",
    "              'class_weight': 'balanced'\n",
    "             }\n",
    "clf, hyperparam_table = train_eval(filename, hyper_dict, hyperparam_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3249: DtypeWarning: Columns (34,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "# Use cleaned data file with NLP features\n",
    "filename = 'data/data_cleanednlp4.csv'\n",
    "hyper_dict = {'test_size': 0.05, \n",
    "              'random_state': 0, \n",
    "              'data_size': None,\n",
    "              'scaling': None,\n",
    "              'filename': filename,\n",
    "              'model': XGBClassifier,\n",
    "              'class_weight': None\n",
    "             }\n",
    "clf, hyperparam_table = train_eval(filename, hyper_dict, hyperparam_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>data_size</th>\n",
       "      <th>scaling</th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.248210</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.248210</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 61)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/data_cleanednlp4.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.765031</td>\n",
       "      <td>0.818208</td>\n",
       "      <td>2227</td>\n",
       "      <td>195</td>\n",
       "      <td>571</td>\n",
       "      <td>267</td>\n",
       "      <td>0.410769</td>\n",
       "      <td>0.577922</td>\n",
       "      <td>0.318616</td>\n",
       "      <td>[0.01426685, 0.022147033, 0.055169754, 0.07037...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state    data_size scaling                      filename                                    model class_weight  test_score  train_score    tn   fp   fn   tp  f1_score  \\\n",
       "0       0.05             0   (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.761656     0.793260  2275  147  630  208  0.348701   \n",
       "1       0.05             0   (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>     balanced    0.761656     0.793260  2275  147  630  208  0.348701   \n",
       "2       0.05             0  (65188, 61)    None     data/data_cleanednlp4.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.765031     0.818208  2227  195  571  267  0.410769   \n",
       "\n",
       "   precision    recall                                feature_importances  \n",
       "0   0.585915  0.248210    [0.13841417, 0.11646682, 0.33226815, 0.4128508]  \n",
       "1   0.585915  0.248210    [0.13841417, 0.11646682, 0.33226815, 0.4128508]  \n",
       "2   0.577922  0.318616  [0.01426685, 0.022147033, 0.055169754, 0.07037...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp = pd.DataFrame(hyperparam_table)\n",
    "df_hyp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (34,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/gksullan/Documents/Springboard/Capstone_Project_1/conflicting_geneticvariants/hyperparamfuncs.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(axis=1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_co...\n",
       "                                           validate_parameters=False,\n",
       "                                           verbosity=None),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'colsample_bytree': [0.5, 0.7, 0.9,\n",
       "                                                             1.0],\n",
       "                                        'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.1, 0.15, 0.2, 0.25,\n",
       "                                                          0.3],\n",
       "                                        'max_depth': [5, 7, 10, None],\n",
       "                                        'n_estimators': [50, 100, 300, 500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use RandomizedSearchCV to find the best hyperparameters for this model\n",
    "filename = 'data/data_cleanednlp4.csv'\n",
    "param_dist = {'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3],\n",
    "              \"max_depth\": [5, 7, 10, None],\n",
    "              \"colsample_bytree\": [0.5, 0.7, 0.9, 1.0],\n",
    "              \"n_estimators\": [50, 100, 300, 500],\n",
    "              \"gamma\": [0, 0.1, 0.2, 0.3, 0.4, 0.5]}\n",
    "df = pd.read_csv(filename)\n",
    "df, var_class = preprocess_data(df)\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, var_class,\n",
    "                                                    test_size=hyper_dict['test_size'],\n",
    "                                                    random_state=hyper_dict['random_state'])\n",
    "# Instantiate a XGBoost classifier\n",
    "clf = XGBClassifier(random_state=0)\n",
    "\n",
    "# Instantiate the RandomizedSearchCV object\n",
    "clf_cv = RandomizedSearchCV(clf, param_dist, scoring='f1', cv=2)\n",
    "\n",
    "# Fit it to the data\n",
    "clf_cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned XGBoost Parameters: {'n_estimators': 500, 'max_depth': 7, 'learning_rate': 0.25, 'gamma': 0.4, 'colsample_bytree': 0.9}\n",
      "Best score is 0.6227965658695761\n"
     ]
    }
   ],
   "source": [
    "# preview the best parameters and score\n",
    "print(f\"Tuned XGBoost Parameters: {clf_cv.best_params_}\")\n",
    "print(f\"Best score is {clf_cv.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_params = clf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this model with the best params, predict labels on test data\n",
    "hyper_dict = {'test_size': 0.05, \n",
    "              'random_state': 0, \n",
    "              'data_size': str(df.shape),\n",
    "              'scaling': None,\n",
    "              'filename': filename,\n",
    "              'model': XGBClassifier\n",
    "             }\n",
    "clf = XGBClassifier(random_state=0)\n",
    "clf.set_params(**cv_params)\n",
    "hyper_dict.update(cv_params)\n",
    "hyperparam_table += [hyper_dict]\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "score = clf.score(x_test,y_test)\n",
    "hyperparam_table[-1]['test_score'] = score\n",
    "training_score = clf.score(x_train,y_train)\n",
    "hyperparam_table[-1]['train_score'] = training_score\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test,pred).ravel()\n",
    "hyperparam_table[-1]['tn'] = tn\n",
    "hyperparam_table[-1]['fp'] = fp\n",
    "hyperparam_table[-1]['fn'] = fn\n",
    "hyperparam_table[-1]['tp'] = tp\n",
    "\n",
    "f1 = f1_score(y_test,pred)\n",
    "hyperparam_table[-1]['f1_score'] = f1\n",
    "precision = precision_score(y_test,pred)\n",
    "hyperparam_table[-1]['precision'] = precision\n",
    "recall = recall_score(y_test,pred)\n",
    "hyperparam_table[-1]['recall'] = recall\n",
    "\n",
    "hyperparam_table[-1]['feature_importances'] = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>data_size</th>\n",
       "      <th>scaling</th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>class_weight</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>feature_importances</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>gamma</th>\n",
       "      <th>colsample_bytree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.248210</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/clinvar_conflicting.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.761656</td>\n",
       "      <td>0.793260</td>\n",
       "      <td>2275</td>\n",
       "      <td>147</td>\n",
       "      <td>630</td>\n",
       "      <td>208</td>\n",
       "      <td>0.348701</td>\n",
       "      <td>0.585915</td>\n",
       "      <td>0.248210</td>\n",
       "      <td>[0.13841417, 0.11646682, 0.33226815, 0.4128508]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 61)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/data_cleanednlp4.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>None</td>\n",
       "      <td>0.765031</td>\n",
       "      <td>0.818208</td>\n",
       "      <td>2227</td>\n",
       "      <td>195</td>\n",
       "      <td>571</td>\n",
       "      <td>267</td>\n",
       "      <td>0.410769</td>\n",
       "      <td>0.577922</td>\n",
       "      <td>0.318616</td>\n",
       "      <td>[0.01426685, 0.022147033, 0.055169754, 0.07037...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 61)</td>\n",
       "      <td>None</td>\n",
       "      <td>data/data_cleanednlp4.csv</td>\n",
       "      <td>&lt;class 'xgboost.sklearn.XGBClassifier'&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769325</td>\n",
       "      <td>0.926221</td>\n",
       "      <td>2203</td>\n",
       "      <td>219</td>\n",
       "      <td>533</td>\n",
       "      <td>305</td>\n",
       "      <td>0.447871</td>\n",
       "      <td>0.582061</td>\n",
       "      <td>0.363962</td>\n",
       "      <td>[0.015140971, 0.018364254, 0.024925346, 0.0488...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state    data_size scaling                      filename                                    model class_weight  test_score  train_score    tn   fp   fn   tp  f1_score  \\\n",
       "0       0.05             0   (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.761656     0.793260  2275  147  630  208  0.348701   \n",
       "1       0.05             0   (65188, 4)    None  data/clinvar_conflicting.csv  <class 'xgboost.sklearn.XGBClassifier'>     balanced    0.761656     0.793260  2275  147  630  208  0.348701   \n",
       "2       0.05             0  (65188, 61)    None     data/data_cleanednlp4.csv  <class 'xgboost.sklearn.XGBClassifier'>         None    0.765031     0.818208  2227  195  571  267  0.410769   \n",
       "3       0.05             0  (65188, 61)    None     data/data_cleanednlp4.csv  <class 'xgboost.sklearn.XGBClassifier'>          NaN    0.769325     0.926221  2203  219  533  305  0.447871   \n",
       "\n",
       "   precision    recall                                feature_importances  n_estimators  max_depth  learning_rate  gamma  colsample_bytree  \n",
       "0   0.585915  0.248210    [0.13841417, 0.11646682, 0.33226815, 0.4128508]           NaN        NaN            NaN    NaN               NaN  \n",
       "1   0.585915  0.248210    [0.13841417, 0.11646682, 0.33226815, 0.4128508]           NaN        NaN            NaN    NaN               NaN  \n",
       "2   0.577922  0.318616  [0.01426685, 0.022147033, 0.055169754, 0.07037...           NaN        NaN            NaN    NaN               NaN  \n",
       "3   0.582061  0.363962  [0.015140971, 0.018364254, 0.024925346, 0.0488...         500.0        7.0           0.25    0.4               0.9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp = pd.DataFrame(hyperparam_table)\n",
    "df_hyp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the hyperparameter table to a .pickle file\n",
    "time = datetime.now().strftime(\"%Y%m%d_%H:%M:%S\")\n",
    "filename = 'hyperparameter_tables/hyperparameter_table'+time+'.pkl'\n",
    "df_hyp.to_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
