{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns=1000\n",
    "pd.options.display.width=200\n",
    "pd.options.display.min_rows=60\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dicts(a,b,ignore=['test_score','train_score','tn','fn','tp','fp','f1_score','precision','recall']):\n",
    "    a = dict(a)\n",
    "    b = dict(b)\n",
    "    for k in ignore:\n",
    "        a.pop(k,None)\n",
    "        b.pop(k,None)\n",
    "        \n",
    "    return tuple(a.items()) == tuple(b.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0,38,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "filename = 'clinvar_conflicting.csv'\n",
    "df =  pd.read_csv(filename)\n",
    "\n",
    "#select only columns with int or float data types\n",
    "df = df.select_dtypes(['number'])\n",
    "#drop any columns with null values\n",
    "df.dropna(axis=1,inplace=True)\n",
    "#remove the class series\n",
    "var_class = df.pop('CLASS')\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(df,var_class,test_size=0.05,random_state=0)\n",
    "x_train.to_csv(filename[:-4]+'_xtrain.csv',index=False)\n",
    "x_test.to_csv(filename[:-4]+'_xtest.csv',index=False)\n",
    "y_train.to_csv(filename[:-4]+'_ytrain.csv',index=False,header=False)\n",
    "y_test.to_csv(filename[:-4]+'_ytest.csv',index=False,header=False)\n",
    "\n",
    "exists = any([compare_dicts(a,b={'test_size': 0.05, \n",
    "                                'random_state': 0, \n",
    "                                'data_size': str(df.shape),\n",
    "                                'scaling':'no_scaling',\n",
    "                                'filename': filename,\n",
    "                                'model': 'sklearn.RandomForestClassifier'\n",
    "                                }) \n",
    "              for a in hyperparam_table])\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "if not exists:\n",
    "    hyperparam_table += [{'test_size': 0.05, \n",
    "                          'random_state': 0, \n",
    "                          'data_size': str(df.shape),\n",
    "                          'scaling':'no_scaling',\n",
    "                          'filename': filename,\n",
    "                          'model': 'sklearn.DecisionTreeClassifier'\n",
    "                         }]\n",
    "        \n",
    "    clf = clf.fit(x_train,y_train)\n",
    "    \n",
    "    predictions_test = clf.predict(X=x_test)\n",
    "    predictions_train = clf.predict(X=x_train)\n",
    "    \n",
    "    score = clf.score(x_test,y_test)\n",
    "    hyperparam_table[-1]['test_score'] = score\n",
    "    \n",
    "    training_score = clf.score(x_train,y_train)\n",
    "    hyperparam_table[-1]['train_score'] = training_score\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,predictions_test).ravel()\n",
    "    hyperparam_table[-1]['tn'] = tn\n",
    "    hyperparam_table[-1]['fp'] = fp\n",
    "    hyperparam_table[-1]['fn'] = fn\n",
    "    hyperparam_table[-1]['tp'] = tp\n",
    "    \n",
    "    f1 = f1_score(y_test,predictions_test)\n",
    "    hyperparam_table[-1]['f1_score'] = f1\n",
    "    precision = precision_score(y_test,predictions_test)\n",
    "    hyperparam_table[-1]['precision'] = precision\n",
    "    recall = recall_score(y_test,predictions_test)\n",
    "    hyperparam_table[-1]['recall'] = recall\n",
    "    hyperparam_table[-1]['feature_importances'] = clf.feature_importances_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>data_size</th>\n",
       "      <th>scaling</th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>no_scaling</td>\n",
       "      <td>clinvar_conflicting.csv</td>\n",
       "      <td>sklearn.DecisionTreeClassifier</td>\n",
       "      <td>0.721166</td>\n",
       "      <td>0.966025</td>\n",
       "      <td>2095</td>\n",
       "      <td>327</td>\n",
       "      <td>582</td>\n",
       "      <td>256</td>\n",
       "      <td>0.36031</td>\n",
       "      <td>0.439108</td>\n",
       "      <td>0.305489</td>\n",
       "      <td>[0.613457760979103, 0.09308880732967509, 0.187...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state   data_size     scaling                 filename                           model  test_score  train_score    tn   fp   fn   tp  f1_score  precision    recall  \\\n",
       "0       0.05             0  (65188, 4)  no_scaling  clinvar_conflicting.csv  sklearn.DecisionTreeClassifier    0.721166     0.966025  2095  327  582  256   0.36031   0.439108  0.305489   \n",
       "\n",
       "                                 feature_importances  \n",
       "0  [0.613457760979103, 0.09308880732967509, 0.187...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp = pd.DataFrame(hyperparam_table)\n",
    "df_hyp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61345776 0.09308881 0.18779581 0.10565762]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (36,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/gksullan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "filename = 'data_cleanednlp2.csv'\n",
    "df =  pd.read_csv(filename, index_col=0)\n",
    "\n",
    "#select only columns with int or float data types\n",
    "df = df.select_dtypes(['number'])\n",
    "#drop any columns with null values\n",
    "df.dropna(axis=1,inplace=True)\n",
    "#remove the class series\n",
    "var_class = df.pop('CLASS')\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(df,var_class,test_size=0.05,random_state=0)\n",
    "x_train.to_csv(filename[:-4]+'_xtrain.csv',index=False)\n",
    "x_test.to_csv(filename[:-4]+'_xtest.csv',index=False)\n",
    "y_train.to_csv(filename[:-4]+'_ytrain.csv',index=False,header=False)\n",
    "y_test.to_csv(filename[:-4]+'_ytest.csv',index=False,header=False)\n",
    "\n",
    "exists = any([compare_dicts(a,b={'test_size': 0.05, \n",
    "                                'random_state': 0, \n",
    "                                'data_size': str(df.shape),\n",
    "                                'scaling':'no_scaling',\n",
    "                                'filename': filename,\n",
    "                                'model': 'sklearn.RandomForestClassifier'\n",
    "                                }) \n",
    "              for a in hyperparam_table])\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "if not exists:\n",
    "    hyperparam_table += [{'test_size': 0.05, \n",
    "                          'random_state': 0, \n",
    "                          'data_size': str(df.shape),\n",
    "                          'scaling':'no_scaling',\n",
    "                          'filename': filename,\n",
    "                          'model': 'sklearn.DecisionTreeClassifier'\n",
    "                         }]\n",
    "        \n",
    "    clf = clf.fit(x_train,y_train)\n",
    "    \n",
    "    predictions_test = clf.predict(X=x_test)\n",
    "    predictions_train = clf.predict(X=x_train)\n",
    "    \n",
    "    score = clf.score(x_test,y_test)\n",
    "    hyperparam_table[-1]['test_score'] = score\n",
    "    \n",
    "    training_score = clf.score(x_train,y_train)\n",
    "    hyperparam_table[-1]['train_score'] = training_score\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,predictions_test).ravel()\n",
    "    hyperparam_table[-1]['tn'] = tn\n",
    "    hyperparam_table[-1]['fp'] = fp\n",
    "    hyperparam_table[-1]['fn'] = fn\n",
    "    hyperparam_table[-1]['tp'] = tp\n",
    "    \n",
    "    f1 = f1_score(y_test,predictions_test)\n",
    "    hyperparam_table[-1]['f1_score'] = f1\n",
    "    precision = precision_score(y_test,predictions_test)\n",
    "    hyperparam_table[-1]['precision'] = precision\n",
    "    recall = recall_score(y_test,predictions_test)\n",
    "    hyperparam_table[-1]['recall'] = recall\n",
    "    hyperparam_table[-1]['feature_importances'] = clf.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_size</th>\n",
       "      <th>random_state</th>\n",
       "      <th>data_size</th>\n",
       "      <th>scaling</th>\n",
       "      <th>filename</th>\n",
       "      <th>model</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 4)</td>\n",
       "      <td>no_scaling</td>\n",
       "      <td>clinvar_conflicting.csv</td>\n",
       "      <td>sklearn.DecisionTreeClassifier</td>\n",
       "      <td>0.721166</td>\n",
       "      <td>0.966025</td>\n",
       "      <td>2095</td>\n",
       "      <td>327</td>\n",
       "      <td>582</td>\n",
       "      <td>256</td>\n",
       "      <td>0.360310</td>\n",
       "      <td>0.439108</td>\n",
       "      <td>0.305489</td>\n",
       "      <td>[0.613457760979103, 0.09308880732967509, 0.187...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>(65188, 55)</td>\n",
       "      <td>no_scaling</td>\n",
       "      <td>data_cleanednlp2.csv</td>\n",
       "      <td>sklearn.DecisionTreeClassifier</td>\n",
       "      <td>0.737117</td>\n",
       "      <td>0.980041</td>\n",
       "      <td>2210</td>\n",
       "      <td>212</td>\n",
       "      <td>645</td>\n",
       "      <td>193</td>\n",
       "      <td>0.310539</td>\n",
       "      <td>0.476543</td>\n",
       "      <td>0.230310</td>\n",
       "      <td>[0.1479280709198763, 0.07932871247184145, 0.12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_size  random_state    data_size     scaling                 filename                           model  test_score  train_score    tn   fp   fn   tp  f1_score  precision    recall  \\\n",
       "0       0.05             0   (65188, 4)  no_scaling  clinvar_conflicting.csv  sklearn.DecisionTreeClassifier    0.721166     0.966025  2095  327  582  256  0.360310   0.439108  0.305489   \n",
       "1       0.05             0  (65188, 55)  no_scaling     data_cleanednlp2.csv  sklearn.DecisionTreeClassifier    0.737117     0.980041  2210  212  645  193  0.310539   0.476543  0.230310   \n",
       "\n",
       "                                 feature_importances  \n",
       "0  [0.613457760979103, 0.09308880732967509, 0.187...  \n",
       "1  [0.1479280709198763, 0.07932871247184145, 0.12...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hyp = pd.DataFrame(hyperparam_table)\n",
    "df_hyp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
